#!/usr/bin/env python

import rospy
from geometry_msgs.msg import Vector3, TransformStamped, Quaternion
from mess_msgs.msg import UAV2MESSCV
from std_msgs.msg import Bool

import cv2
import json
import numpy as np
import os.path

##################################################################################

#
f = open(os.path.dirname(__file__) + "/../../json/remote.json")
fData = json.load(f)

#
class labEnvironment():
    def __init__(self, xmin, xmax, ymin, ymax, res):

        #
        self.domainX = np.arange(xmin, xmax, res)
        self.domainY = np.arange(ymin, ymax, res)
        globalX, globalY = np.meshgrid(self.domainX, self.domainY)
        globalR = np.zeros((globalX.shape[0], globalX.shape[1]))
        globalG = np.zeros((globalX.shape[0], globalX.shape[1]))
        globalB = np.zeros((globalX.shape[0], globalX.shape[1]))
        globalN = np.zeros((globalX.shape[0], globalX.shape[1]))

        #
        self.env = np.stack((globalX, globalY, globalR, globalG, globalB, globalN), axis=2)

##################################################################################

def callbackVL(data):
    
    # Check if image is being processed:
    if canSampleVL.data:

        # Prevent images from being sampled until current image is processed:
        canSampleVL.data = False

        # Retrieve image:
        array = np.frombuffer(data.data, np.uint8)
        image = cv2.imdecode(array, cv2.IMREAD_COLOR)

        # Retrieve UAV pose:
        pose = TransformStamped()
        pose.transform.translation.x = data.transform.translation.x
        pose.transform.translation.y = data.transform.translation.y
        pose.transform.translation.z = data.transform.translation.z
        pose.transform.rotation.x = data.transform.rotation.x
        pose.transform.rotation.y = data.transform.rotation.y
        pose.transform.rotation.z = data.transform.rotation.z
        pose.transform.rotation.w = data.transform.rotation.w

        # Retrieve camera optics:
        optics = data.optics

        # Update VL environment matrix:
        if image is not None:
            processImage(environmentVL, image, pose, optics)

        # Allow new images to be sampled and processed:
        canSampleVL.data = True


def callbackIR(data):
    
    # Check if image is being processed:
    if canSampleIR.data:

        # Prevent images from being sampled until current image is processed:
        canSampleIR.data = False

        # Retrieve image:
        array = np.frombuffer(data.data, np.uint8)
        image = cv2.imdecode(array, cv2.IMREAD_COLOR)

        # Retrieve UAV pose:
        pose = TransformStamped()
        pose.transform.translation.x = data.transform.translation.x
        pose.transform.translation.y = data.transform.translation.y
        pose.transform.translation.z = data.transform.translation.z
        pose.transform.rotation.x = data.transform.rotation.x
        pose.transform.rotation.y = data.transform.rotation.y
        pose.transform.rotation.z = data.transform.rotation.z
        pose.transform.rotation.w = data.transform.rotation.w

        # Retrieve camera optics:
        optics = data.optics

        # Update IR environment matrix:
        if image is not None:
            processImage(environmentIR, image, pose, optics)
        
        # Allow new images to be sampled and processed:
        canSampleIR.data = True

##################################################################################

#
def quat2Eul(q):

    # Euler angle form of Quaternion input:
    Rx = np.arctan2(2 * (q.w * q.x + q.y * q.z), 1 - 2 * (q.x ** 2 + q.y ** 2))
    Ry = -0.5 * np.pi + 2 * np.arctan2(np.sqrt(1 + 2 * (q.w * q.y - q.x * q.z)), np.sqrt(1 - 2 * (q.w * q.y - q.x * q.z)))
    Rz = np.arctan2(2 * (q.w * q.z + q.x * q.y), 1 - 2 * (q.y ** 2 + q.z ** 2))

    return Rx, Ry, Rz

#
def vector3Dot(v0, vi):
    return v0.x * vi.x + v0.y * vi.y + v0.z * vi.z

#
def vector3Norm(vi):
    return np.sqrt(vi.x ** 2 + vi.y ** 2 + vi.z ** 2)

#
def getCorner(tx, ty, tz, rx, ry, rz, i, optics):

    # Create surface normal vector:
    v0 = Vector3(0.0, 0.0, -1.0)
    
    # Calculate vector to ith corner:
    vi = Vector3(0.0, 0.0, -1.0)
    if i == 1:
        vi.x = tz * np.tan(rx + 0.5 * optics[0])
        vi.y = tz * np.tan(ry + 0.5 * optics[1])
        vi.z = -tz
    elif i == 2:
        vi.x = tz * np.tan(rx - 0.5 * optics[0])
        vi.y = tz * np.tan(ry + 0.5 * optics[1])
        vi.z = -tz
    elif i == 3:
        vi.x = tz * np.tan(rx - 0.5 * optics[0])
        vi.y = tz * np.tan(ry - 0.5 * optics[1])
        vi.z = -tz
    elif i == 4:
        vi.x = tz * np.tan(rx + 0.5 * optics[0])
        vi.y = tz * np.tan(ry - 0.5 * optics[1])
        vi.z = -tz

    # Calculate normalized distance in threat plane:
    gamma = np.arccos(vector3Dot(v0, vi) / (vector3Norm(v0) * vector3Norm(vi)))
    distance = tz * np.tan(gamma)

    # Calculate heading of corner:
    beta = np.arctan(np.tan(0.5 * optics[1]) / np.tan(0.5 * optics[0]))
    alpha = np.array([beta, np.pi - beta, beta - np.pi, -beta])

    # Calculate corner vertex before camera orientation assumption:
    dx = distance * np.cos(alpha[i - 1])
    dy = distance * np.sin(alpha[i - 1])

    # Rotate corner vertex to match assumed orientation of camera w.r.t UAV:
    dx_ = tx + dx * np.cos(rz - np.pi / 2) - dy * np.sin(rz - np.pi / 2)
    dy_ = ty + dx * np.sin(rz - np.pi / 2) + dy * np.cos(rz - np.pi / 2)

    return Vector3(dx_, dy_, 0.0)

#
def processImage(env, image, pose, optics):

    # Store UAV translation:
    Tx = pose.transform.translation.x
    Ty = pose.transform.translation.y
    Tz = pose.transform.translation.z

    # Store UAV rotation:
    Q = Quaternion()
    Q.x = pose.transform.rotation.x
    Q.y = pose.transform.rotation.y
    Q.z = pose.transform.rotation.z
    Q.w = pose.transform.rotation.w

    # Convert UAV rotation to Euler angle:
    Rx, Ry, Rz = quat2Eul(Q)

    # Retrieve source vertices:
    S1 = getCorner(0.0, 0.0, Tz, 0.0, 0.0, np.pi / 2, 1, optics)
    S2 = getCorner(0.0, 0.0, Tz, 0.0, 0.0, np.pi / 2, 2, optics)
    S3 = getCorner(0.0, 0.0, Tz, 0.0, 0.0, np.pi / 2, 3, optics)
    S4 = getCorner(0.0, 0.0, Tz, 0.0, 0.0, np.pi / 2, 4, optics)

    # Retrieve destination vertices:
    D1 = getCorner(Tx, Ty, Tz, Rx, Ry, Rz, 1, optics)
    D2 = getCorner(Tx, Ty, Tz, Rx, Ry, Rz, 2, optics)
    D3 = getCorner(Tx, Ty, Tz, Rx, Ry, Rz, 3, optics)
    D4 = getCorner(Tx, Ty, Tz, Rx, Ry, Rz, 4, optics)

    # Initialize preliminary homogeneous transformation parameters:
    S_ = np.array([[S1.x, S1.y], [S2.x, S2.y], [S3.x, S3.y], [S4.x, S4.y]])
    D_ = np.array([[D1.x, D1.y], [D2.x, D2.y], [D3.x, D3.y], [D4.x, D4.y]])
    A_ = np.zeros((8, 8), dtype=np.float64)
    C_ = np.zeros((8, 1), dtype=np.float64)

    # Fill A_ and C_ matrices before finding homogeneous transformation matrix:
    for i in range(4):

        # Update first of current rows:
        A_[2 * i, 0] = S_[i, 0]
        A_[2 * i, 1] = S_[i, 1]
        A_[2 * i, 2] = 1.0
        A_[2 * i, -2] = -S_[i, 0] * D_[i, 0]
        A_[2 * i, -1] = -S_[i, 1] * D_[i, 0]
        C_[2 * i, 0] = D_[i, 0]

        # Update second of current rows:
        A_[2 * i + 1, 3] = S_[i, 0]
        A_[2 * i + 1, 4] = S_[i, 1]
        A_[2 * i + 1, 5] = 1.0
        A_[2 * i + 1, -2] = -S_[i, 0] * D_[i, 1]
        A_[2 * i + 1, -1] = -S_[i, 1] * D_[i, 1]
        C_[2 * i + 1, 0] = D_[i, 1]

    # Homogeneous transformation matrix:
    coefficients = np.append(np.dot(np.linalg.inv(A_), C_), np.array([[1.0]]), axis=0)
    H_ = coefficients.reshape((3, 3))

    # Domain and range of image projection:
    X_ = np.linspace(np.min(S_[:, 0]), np.max(S_[:, 0]), image.shape[1])
    Y_ = np.linspace(np.min(S_[:, 1]), np.max(S_[:, 1]), image.shape[0])
    XP_, YP_ = np.meshgrid(X_, Y_)
    XP_ = XP_.reshape(1, -1)
    YP_ = YP_.reshape(1, -1)

    # Transform source matrix to destination matrix:
    source = np.vstack((XP_, YP_, np.ones((1, XP_.shape[1]))))
    destination = np.dot(H_, source)

    # Multiply position in threat plane by homogeneous scale factor:
    projecting = np.vstack((destination[0, :] / destination[2, :], destination[1, :] / destination[2, :]))

    # Scale projection to labResolution:
    projecting = labResolution * np.rint(projecting / labResolution)

    # Sort projection:
    indices = np.lexsort(projecting[0:2, :])
    projection = projecting[:, indices]

    # Retrieve image RGB values:
    rgb_ = np.flip(np.rot90(np.rot90(image)), axis=1).astype("float64")
    RGB_ = np.flip(rgb_.reshape(-1, 3), axis=0).astype("float64")
    R_ = RGB_[indices, 2]
    G_ = RGB_[indices, 1]
    B_ = RGB_[indices, 0]

    #
    col1 = 0
    col2 = 0
    upper = projection.shape[1]
    while col2 < upper - 1:

        # Retrieve column indices of current x-values in projection:
        while projection[0, col1] == projection[0, col2] and col2 < upper - 1:
            col2 += 1

        # Retrieve global index of current x and y vertex:
        xInd = np.where(np.abs(env.domainX - projection[0, col1]) < labResolution ** 2)[0]
        yInd = np.where(np.abs(env.domainY - projection[1, col1]) < labResolution ** 2)[0]

        # Retrieve initial RGB values:
        R0 = env.env[yInd, xInd, 2]
        G0 = env.env[yInd, xInd, 3]
        B0 = env.env[yInd, xInd, 4]
        N0 = env.env[yInd, xInd, 5]

        # Calculate group batch of new RGB values:
        Ni = col2 - col1
        Ri = np.sqrt((R_[col1:col2] ** 2).sum(0) / Ni)
        Gi = np.sqrt((G_[col1:col2] ** 2).sum(0) / Ni)
        Bi = np.sqrt((B_[col1:col2] ** 2).sum(0) / Ni)

        # Update environment:
        env.env[yInd, xInd, 2] = np.sqrt((N0 * R0 ** 2 + Ni * Ri ** 2) / (N0 + Ni))
        env.env[yInd, xInd, 3] = np.sqrt((N0 * G0 ** 2 + Ni * Gi ** 2) / (N0 + Ni))
        env.env[yInd, xInd, 4] = np.sqrt((N0 * B0 ** 2 + Ni * Bi ** 2) / (N0 + Ni))
        env.env[yInd, xInd, 5] += Ni

        # Update column indices for next iteration:
        col1 = col2

##################################################################################

#
if __name__=="__main__":

    # Initialize node:
    rospy.init_node("messcv_threat")

    # Create objects:
    canSampleVL = Bool()
    canSampleVL.data = True
    canSampleIR = Bool()
    canSampleIR.data = True

    # Retrieve messcv data:
    labResolution = fData["lab_res"]
    xMin = fData["xmin"]
    xMax = fData["xmax"]
    yMin = fData["ymin"]
    yMax = fData["ymax"]

    # Create visual light and infrared environments:
    environmentVL = labEnvironment(xMin, xMax, yMin, yMax, labResolution)
    environmentIR = labEnvironment(xMin, xMax, yMin, yMax, labResolution)

    # Initialize publishers and subscribers:
    rospy.Subscriber("/messop/messcv/samples/vl", UAV2MESSCV, callbackVL)
    rospy.Subscriber("/messop/messcv/samples/ir", UAV2MESSCV, callbackIR)

    # Spin until node is shut down:
    rospy.spin()